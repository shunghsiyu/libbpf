From bddb0a057aad9095e760e5ec1d616556547aa499 Mon Sep 17 00:00:00 2001
From: Shung-Hsi Yu <shung-hsi.yu@suse.com>
Date: Sat, 26 Apr 2025 09:15:26 +0000
Subject: [PATCH 5/8] Revert "selftests/bpf: Add tests for rqspinlock"

This reverts commit 60ba5b3ed7278a5700c8d57c3f5486b6066f745c.
---
 .../selftests/bpf/prog_tests/res_spin_lock.c  |  98 -------
 tools/testing/selftests/bpf/progs/irq.c       |  53 ----
 .../selftests/bpf/progs/res_spin_lock.c       | 143 ----------
 .../selftests/bpf/progs/res_spin_lock_fail.c  | 244 ------------------
 4 files changed, 538 deletions(-)
 delete mode 100644 tools/testing/selftests/bpf/prog_tests/res_spin_lock.c
 delete mode 100644 tools/testing/selftests/bpf/progs/res_spin_lock.c
 delete mode 100644 tools/testing/selftests/bpf/progs/res_spin_lock_fail.c

diff --git a/tools/testing/selftests/bpf/prog_tests/res_spin_lock.c b/tools/testing/selftests/bpf/prog_tests/res_spin_lock.c
deleted file mode 100644
index 115287ba441b..000000000000
--- a/tools/testing/selftests/bpf/prog_tests/res_spin_lock.c
+++ /dev/null
@@ -1,98 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/* Copyright (c) 2024-2025 Meta Platforms, Inc. and affiliates. */
-#include <test_progs.h>
-#include <network_helpers.h>
-#include <sys/sysinfo.h>
-
-#include "res_spin_lock.skel.h"
-#include "res_spin_lock_fail.skel.h"
-
-void test_res_spin_lock_failure(void)
-{
-	RUN_TESTS(res_spin_lock_fail);
-}
-
-static volatile int skip;
-
-static void *spin_lock_thread(void *arg)
-{
-	int err, prog_fd = *(u32 *) arg;
-	LIBBPF_OPTS(bpf_test_run_opts, topts,
-		.data_in = &pkt_v4,
-		.data_size_in = sizeof(pkt_v4),
-		.repeat = 10000,
-	);
-
-	while (!READ_ONCE(skip)) {
-		err = bpf_prog_test_run_opts(prog_fd, &topts);
-		ASSERT_OK(err, "test_run");
-		ASSERT_OK(topts.retval, "test_run retval");
-	}
-	pthread_exit(arg);
-}
-
-void test_res_spin_lock_success(void)
-{
-	LIBBPF_OPTS(bpf_test_run_opts, topts,
-		.data_in = &pkt_v4,
-		.data_size_in = sizeof(pkt_v4),
-		.repeat = 1,
-	);
-	struct res_spin_lock *skel;
-	pthread_t thread_id[16];
-	int prog_fd, i, err;
-	void *ret;
-
-	if (get_nprocs() < 2) {
-		test__skip();
-		return;
-	}
-
-	skel = res_spin_lock__open_and_load();
-	if (!ASSERT_OK_PTR(skel, "res_spin_lock__open_and_load"))
-		return;
-	/* AA deadlock */
-	prog_fd = bpf_program__fd(skel->progs.res_spin_lock_test);
-	err = bpf_prog_test_run_opts(prog_fd, &topts);
-	ASSERT_OK(err, "error");
-	ASSERT_OK(topts.retval, "retval");
-
-	prog_fd = bpf_program__fd(skel->progs.res_spin_lock_test_held_lock_max);
-	err = bpf_prog_test_run_opts(prog_fd, &topts);
-	ASSERT_OK(err, "error");
-	ASSERT_OK(topts.retval, "retval");
-
-	/* Multi-threaded ABBA deadlock. */
-
-	prog_fd = bpf_program__fd(skel->progs.res_spin_lock_test_AB);
-	for (i = 0; i < 16; i++) {
-		int err;
-
-		err = pthread_create(&thread_id[i], NULL, &spin_lock_thread, &prog_fd);
-		if (!ASSERT_OK(err, "pthread_create"))
-			goto end;
-	}
-
-	topts.retval = 0;
-	topts.repeat = 1000;
-	int fd = bpf_program__fd(skel->progs.res_spin_lock_test_BA);
-	while (!topts.retval && !err && !READ_ONCE(skel->bss->err)) {
-		err = bpf_prog_test_run_opts(fd, &topts);
-	}
-
-	WRITE_ONCE(skip, true);
-
-	for (i = 0; i < 16; i++) {
-		if (!ASSERT_OK(pthread_join(thread_id[i], &ret), "pthread_join"))
-			goto end;
-		if (!ASSERT_EQ(ret, &prog_fd, "ret == prog_fd"))
-			goto end;
-	}
-
-	ASSERT_EQ(READ_ONCE(skel->bss->err), -EDEADLK, "timeout err");
-	ASSERT_OK(err, "err");
-	ASSERT_EQ(topts.retval, -EDEADLK, "timeout");
-end:
-	res_spin_lock__destroy(skel);
-	return;
-}
diff --git a/tools/testing/selftests/bpf/progs/irq.c b/tools/testing/selftests/bpf/progs/irq.c
index 74d912b22de9..298d48d7886d 100644
--- a/tools/testing/selftests/bpf/progs/irq.c
+++ b/tools/testing/selftests/bpf/progs/irq.c
@@ -11,9 +11,6 @@ extern void bpf_local_irq_save(unsigned long *) __weak __ksym;
 extern void bpf_local_irq_restore(unsigned long *) __weak __ksym;
 extern int bpf_copy_from_user_str(void *dst, u32 dst__sz, const void *unsafe_ptr__ign, u64 flags) __weak __ksym;
 
-struct bpf_res_spin_lock lockA __hidden SEC(".data.A");
-struct bpf_res_spin_lock lockB __hidden SEC(".data.B");
-
 SEC("?tc")
 __failure __msg("arg#0 doesn't point to an irq flag on stack")
 int irq_save_bad_arg(struct __sk_buff *ctx)
@@ -513,54 +510,4 @@ int irq_sleepable_global_subprog_indirect(void *ctx)
 	return 0;
 }
 
-SEC("?tc")
-__failure __msg("cannot restore irq state out of order")
-int irq_ooo_lock_cond_inv(struct __sk_buff *ctx)
-{
-	unsigned long flags1, flags2;
-
-	if (bpf_res_spin_lock_irqsave(&lockA, &flags1))
-		return 0;
-	if (bpf_res_spin_lock_irqsave(&lockB, &flags2)) {
-		bpf_res_spin_unlock_irqrestore(&lockA, &flags1);
-		return 0;
-	}
-
-	bpf_res_spin_unlock_irqrestore(&lockB, &flags1);
-	bpf_res_spin_unlock_irqrestore(&lockA, &flags2);
-	return 0;
-}
-
-SEC("?tc")
-__failure __msg("function calls are not allowed")
-int irq_wrong_kfunc_class_1(struct __sk_buff *ctx)
-{
-	unsigned long flags1;
-
-	if (bpf_res_spin_lock_irqsave(&lockA, &flags1))
-		return 0;
-	/* For now, bpf_local_irq_restore is not allowed in critical section,
-	 * but this test ensures error will be caught with kfunc_class when it's
-	 * opened up. Tested by temporarily permitting this kfunc in critical
-	 * section.
-	 */
-	bpf_local_irq_restore(&flags1);
-	bpf_res_spin_unlock_irqrestore(&lockA, &flags1);
-	return 0;
-}
-
-SEC("?tc")
-__failure __msg("function calls are not allowed")
-int irq_wrong_kfunc_class_2(struct __sk_buff *ctx)
-{
-	unsigned long flags1, flags2;
-
-	bpf_local_irq_save(&flags1);
-	if (bpf_res_spin_lock_irqsave(&lockA, &flags2))
-		return 0;
-	bpf_local_irq_restore(&flags2);
-	bpf_res_spin_unlock_irqrestore(&lockA, &flags1);
-	return 0;
-}
-
 char _license[] SEC("license") = "GPL";
diff --git a/tools/testing/selftests/bpf/progs/res_spin_lock.c b/tools/testing/selftests/bpf/progs/res_spin_lock.c
deleted file mode 100644
index b33385dfbd35..000000000000
--- a/tools/testing/selftests/bpf/progs/res_spin_lock.c
+++ /dev/null
@@ -1,143 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/* Copyright (c) 2024-2025 Meta Platforms, Inc. and affiliates. */
-#include <vmlinux.h>
-#include <bpf/bpf_tracing.h>
-#include <bpf/bpf_helpers.h>
-#include "bpf_misc.h"
-
-#define EDEADLK 35
-#define ETIMEDOUT 110
-
-struct arr_elem {
-	struct bpf_res_spin_lock lock;
-};
-
-struct {
-	__uint(type, BPF_MAP_TYPE_ARRAY);
-	__uint(max_entries, 64);
-	__type(key, int);
-	__type(value, struct arr_elem);
-} arrmap SEC(".maps");
-
-struct bpf_res_spin_lock lockA __hidden SEC(".data.A");
-struct bpf_res_spin_lock lockB __hidden SEC(".data.B");
-
-SEC("tc")
-int res_spin_lock_test(struct __sk_buff *ctx)
-{
-	struct arr_elem *elem1, *elem2;
-	int r;
-
-	elem1 = bpf_map_lookup_elem(&arrmap, &(int){0});
-	if (!elem1)
-		return -1;
-	elem2 = bpf_map_lookup_elem(&arrmap, &(int){0});
-	if (!elem2)
-		return -1;
-
-	r = bpf_res_spin_lock(&elem1->lock);
-	if (r)
-		return r;
-	if (!bpf_res_spin_lock(&elem2->lock)) {
-		bpf_res_spin_unlock(&elem2->lock);
-		bpf_res_spin_unlock(&elem1->lock);
-		return -1;
-	}
-	bpf_res_spin_unlock(&elem1->lock);
-	return 0;
-}
-
-SEC("tc")
-int res_spin_lock_test_AB(struct __sk_buff *ctx)
-{
-	int r;
-
-	r = bpf_res_spin_lock(&lockA);
-	if (r)
-		return !r;
-	/* Only unlock if we took the lock. */
-	if (!bpf_res_spin_lock(&lockB))
-		bpf_res_spin_unlock(&lockB);
-	bpf_res_spin_unlock(&lockA);
-	return 0;
-}
-
-int err;
-
-SEC("tc")
-int res_spin_lock_test_BA(struct __sk_buff *ctx)
-{
-	int r;
-
-	r = bpf_res_spin_lock(&lockB);
-	if (r)
-		return !r;
-	if (!bpf_res_spin_lock(&lockA))
-		bpf_res_spin_unlock(&lockA);
-	else
-		err = -EDEADLK;
-	bpf_res_spin_unlock(&lockB);
-	return err ?: 0;
-}
-
-SEC("tc")
-int res_spin_lock_test_held_lock_max(struct __sk_buff *ctx)
-{
-	struct bpf_res_spin_lock *locks[48] = {};
-	struct arr_elem *e;
-	u64 time_beg, time;
-	int ret = 0, i;
-
-	_Static_assert(ARRAY_SIZE(((struct rqspinlock_held){}).locks) == 31,
-		       "RES_NR_HELD assumed to be 31");
-
-	for (i = 0; i < 34; i++) {
-		int key = i;
-
-		/* We cannot pass in i as it will get spilled/filled by the compiler and
-		 * loses bounds in verifier state.
-		 */
-		e = bpf_map_lookup_elem(&arrmap, &key);
-		if (!e)
-			return 1;
-		locks[i] = &e->lock;
-	}
-
-	for (; i < 48; i++) {
-		int key = i - 2;
-
-		/* We cannot pass in i as it will get spilled/filled by the compiler and
-		 * loses bounds in verifier state.
-		 */
-		e = bpf_map_lookup_elem(&arrmap, &key);
-		if (!e)
-			return 1;
-		locks[i] = &e->lock;
-	}
-
-	time_beg = bpf_ktime_get_ns();
-	for (i = 0; i < 34; i++) {
-		if (bpf_res_spin_lock(locks[i]))
-			goto end;
-	}
-
-	/* Trigger AA, after exhausting entries in the held lock table. This
-	 * time, only the timeout can save us, as AA detection won't succeed.
-	 */
-	if (!bpf_res_spin_lock(locks[34])) {
-		bpf_res_spin_unlock(locks[34]);
-		ret = 1;
-		goto end;
-	}
-
-end:
-	for (i = i - 1; i >= 0; i--)
-		bpf_res_spin_unlock(locks[i]);
-	time = bpf_ktime_get_ns() - time_beg;
-	/* Time spent should be easily above our limit (1/4 s), since AA
-	 * detection won't be expedited due to lack of held lock entry.
-	 */
-	return ret ?: (time > 1000000000 / 4 ? 0 : 1);
-}
-
-char _license[] SEC("license") = "GPL";
diff --git a/tools/testing/selftests/bpf/progs/res_spin_lock_fail.c b/tools/testing/selftests/bpf/progs/res_spin_lock_fail.c
deleted file mode 100644
index 330682a88c16..000000000000
--- a/tools/testing/selftests/bpf/progs/res_spin_lock_fail.c
+++ /dev/null
@@ -1,244 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/* Copyright (c) 2024-2025 Meta Platforms, Inc. and affiliates. */
-#include <vmlinux.h>
-#include <bpf/bpf_tracing.h>
-#include <bpf/bpf_helpers.h>
-#include <bpf/bpf_core_read.h>
-#include "bpf_misc.h"
-#include "bpf_experimental.h"
-
-struct arr_elem {
-	struct bpf_res_spin_lock lock;
-};
-
-struct {
-	__uint(type, BPF_MAP_TYPE_ARRAY);
-	__uint(max_entries, 1);
-	__type(key, int);
-	__type(value, struct arr_elem);
-} arrmap SEC(".maps");
-
-long value;
-
-struct bpf_spin_lock lock __hidden SEC(".data.A");
-struct bpf_res_spin_lock res_lock __hidden SEC(".data.B");
-
-SEC("?tc")
-__failure __msg("point to map value or allocated object")
-int res_spin_lock_arg(struct __sk_buff *ctx)
-{
-	struct arr_elem *elem;
-
-	elem = bpf_map_lookup_elem(&arrmap, &(int){0});
-	if (!elem)
-		return 0;
-	bpf_res_spin_lock((struct bpf_res_spin_lock *)bpf_core_cast(&elem->lock, struct __sk_buff));
-	bpf_res_spin_lock(&elem->lock);
-	return 0;
-}
-
-SEC("?tc")
-__failure __msg("AA deadlock detected")
-int res_spin_lock_AA(struct __sk_buff *ctx)
-{
-	struct arr_elem *elem;
-
-	elem = bpf_map_lookup_elem(&arrmap, &(int){0});
-	if (!elem)
-		return 0;
-	bpf_res_spin_lock(&elem->lock);
-	bpf_res_spin_lock(&elem->lock);
-	return 0;
-}
-
-SEC("?tc")
-__failure __msg("AA deadlock detected")
-int res_spin_lock_cond_AA(struct __sk_buff *ctx)
-{
-	struct arr_elem *elem;
-
-	elem = bpf_map_lookup_elem(&arrmap, &(int){0});
-	if (!elem)
-		return 0;
-	if (bpf_res_spin_lock(&elem->lock))
-		return 0;
-	bpf_res_spin_lock(&elem->lock);
-	return 0;
-}
-
-SEC("?tc")
-__failure __msg("unlock of different lock")
-int res_spin_lock_mismatch_1(struct __sk_buff *ctx)
-{
-	struct arr_elem *elem;
-
-	elem = bpf_map_lookup_elem(&arrmap, &(int){0});
-	if (!elem)
-		return 0;
-	if (bpf_res_spin_lock(&elem->lock))
-		return 0;
-	bpf_res_spin_unlock(&res_lock);
-	return 0;
-}
-
-SEC("?tc")
-__failure __msg("unlock of different lock")
-int res_spin_lock_mismatch_2(struct __sk_buff *ctx)
-{
-	struct arr_elem *elem;
-
-	elem = bpf_map_lookup_elem(&arrmap, &(int){0});
-	if (!elem)
-		return 0;
-	if (bpf_res_spin_lock(&res_lock))
-		return 0;
-	bpf_res_spin_unlock(&elem->lock);
-	return 0;
-}
-
-SEC("?tc")
-__failure __msg("unlock of different lock")
-int res_spin_lock_irq_mismatch_1(struct __sk_buff *ctx)
-{
-	struct arr_elem *elem;
-	unsigned long f1;
-
-	elem = bpf_map_lookup_elem(&arrmap, &(int){0});
-	if (!elem)
-		return 0;
-	bpf_local_irq_save(&f1);
-	if (bpf_res_spin_lock(&res_lock))
-		return 0;
-	bpf_res_spin_unlock_irqrestore(&res_lock, &f1);
-	return 0;
-}
-
-SEC("?tc")
-__failure __msg("unlock of different lock")
-int res_spin_lock_irq_mismatch_2(struct __sk_buff *ctx)
-{
-	struct arr_elem *elem;
-	unsigned long f1;
-
-	elem = bpf_map_lookup_elem(&arrmap, &(int){0});
-	if (!elem)
-		return 0;
-	if (bpf_res_spin_lock_irqsave(&res_lock, &f1))
-		return 0;
-	bpf_res_spin_unlock(&res_lock);
-	return 0;
-}
-
-SEC("?tc")
-__success
-int res_spin_lock_ooo(struct __sk_buff *ctx)
-{
-	struct arr_elem *elem;
-
-	elem = bpf_map_lookup_elem(&arrmap, &(int){0});
-	if (!elem)
-		return 0;
-	if (bpf_res_spin_lock(&res_lock))
-		return 0;
-	if (bpf_res_spin_lock(&elem->lock)) {
-		bpf_res_spin_unlock(&res_lock);
-		return 0;
-	}
-	bpf_res_spin_unlock(&elem->lock);
-	bpf_res_spin_unlock(&res_lock);
-	return 0;
-}
-
-SEC("?tc")
-__success
-int res_spin_lock_ooo_irq(struct __sk_buff *ctx)
-{
-	struct arr_elem *elem;
-	unsigned long f1, f2;
-
-	elem = bpf_map_lookup_elem(&arrmap, &(int){0});
-	if (!elem)
-		return 0;
-	if (bpf_res_spin_lock_irqsave(&res_lock, &f1))
-		return 0;
-	if (bpf_res_spin_lock_irqsave(&elem->lock, &f2)) {
-		bpf_res_spin_unlock_irqrestore(&res_lock, &f1);
-		/* We won't have a unreleased IRQ flag error here. */
-		return 0;
-	}
-	bpf_res_spin_unlock_irqrestore(&elem->lock, &f2);
-	bpf_res_spin_unlock_irqrestore(&res_lock, &f1);
-	return 0;
-}
-
-struct bpf_res_spin_lock lock1 __hidden SEC(".data.OO1");
-struct bpf_res_spin_lock lock2 __hidden SEC(".data.OO2");
-
-SEC("?tc")
-__failure __msg("bpf_res_spin_unlock cannot be out of order")
-int res_spin_lock_ooo_unlock(struct __sk_buff *ctx)
-{
-	if (bpf_res_spin_lock(&lock1))
-		return 0;
-	if (bpf_res_spin_lock(&lock2)) {
-		bpf_res_spin_unlock(&lock1);
-		return 0;
-	}
-	bpf_res_spin_unlock(&lock1);
-	bpf_res_spin_unlock(&lock2);
-	return 0;
-}
-
-SEC("?tc")
-__failure __msg("off 1 doesn't point to 'struct bpf_res_spin_lock' that is at 0")
-int res_spin_lock_bad_off(struct __sk_buff *ctx)
-{
-	struct arr_elem *elem;
-
-	elem = bpf_map_lookup_elem(&arrmap, &(int){0});
-	if (!elem)
-		return 0;
-	bpf_res_spin_lock((void *)&elem->lock + 1);
-	return 0;
-}
-
-SEC("?tc")
-__failure __msg("R1 doesn't have constant offset. bpf_res_spin_lock has to be at the constant offset")
-int res_spin_lock_var_off(struct __sk_buff *ctx)
-{
-	struct arr_elem *elem;
-	u64 val = value;
-
-	elem = bpf_map_lookup_elem(&arrmap, &(int){0});
-	if (!elem) {
-		// FIXME: Only inline assembly use in assert macro doesn't emit
-		//	  BTF definition.
-		bpf_throw(0);
-		return 0;
-	}
-	bpf_assert_range(val, 0, 40);
-	bpf_res_spin_lock((void *)&value + val);
-	return 0;
-}
-
-SEC("?tc")
-__failure __msg("map 'res_spin.bss' has no valid bpf_res_spin_lock")
-int res_spin_lock_no_lock_map(struct __sk_buff *ctx)
-{
-	bpf_res_spin_lock((void *)&value + 1);
-	return 0;
-}
-
-SEC("?tc")
-__failure __msg("local 'kptr' has no valid bpf_res_spin_lock")
-int res_spin_lock_no_lock_kptr(struct __sk_buff *ctx)
-{
-	struct { int i; } *p = bpf_obj_new(typeof(*p));
-
-	if (!p)
-		return 0;
-	bpf_res_spin_lock((void *)p);
-	return 0;
-}
-
-char _license[] SEC("license") = "GPL";
-- 
2.49.0

